[project]
name = "transformers-stack"
version = "0.1.0"
description = "A cohesive Transformers stack built on PyTorch with uv for reproducible dependency management"
readme = "README.md"
requires-python = ">=3.10"
authors = [
    { name = "EvalOps", email = "contact@evalops.com" }
]

dependencies = [
  "torch==2.8.0",
  "transformers[torch]==4.56.2",
  "datasets==4.1.1",
  "evaluate>=0.4.1",
  "scikit-learn>=1.3",
  # performance & fine-tuning
  "accelerate==1.10.1",
  "peft==0.17.1",
  # utilities
  "sentencepiece>=0.1.99",
  "tqdm>=4.66",
]

[project.optional-dependencies]
cuda = [
  # CUDA-only packages (Linux/Windows with NVIDIA GPU)
  "bitsandbytes==0.47.0",
  "flash-attn==2.8.3",
  "xformers==0.0.32.post2",
  "vllm==0.10.2",
]
tracking = [
  # Experiment tracking and model registry
  "wandb>=0.17",
  "mlflow>=2.12",
]
serve = [
  # Model serving and monitoring
  "fastapi>=0.115",
  "uvicorn[standard]>=0.30",
  "prometheus-fastapi-instrumentator>=7.0",
  "pydantic>=2.0",
]
export = [
  # Model export and optimization
  "onnx>=1.16",
  "onnxruntime>=1.18",
  "optimum>=1.23",
]
tooling = [
  # Configuration and utilities
  "hydra-core>=1.3",
  "typer>=0.12",
  "rich>=13.7",
  "python-dotenv>=1.0",
]
dev = [
  "ruff",
  "black",
  "pytest",
  "pytest-cov",
  "pytest-xdist",
  "pytest-timeout",
  "mypy",
  "pre-commit",
  "ipykernel",
  "mkdocs-material",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
